# suc-model-on-zig-Inference-and-server
run huggingface model on cpu or gpu locall in zig Language Faster than python
